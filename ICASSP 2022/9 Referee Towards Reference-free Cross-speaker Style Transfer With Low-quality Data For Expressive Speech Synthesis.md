# Referee: Towards Reference-free Cross-speaker Style Transfer With Low-quality Data For Expressive Speech Synthesis

[arxiv](https://arxiv.org/pdf/2109.03439.pdf) | code | [sample](https://liusongxiang.github.io/Referee/)

<p align=center>
    <img alt="图 8" src="../img/9%20Referee%20Towards%20Reference-free%20Cross-speaker%20Style%20Transfer%20With%20Low-quality%20Data%20For%20Expressive%20Speech%20Synthesis/IMG_20220308-155042427.png", width='80%'>
</p>

## Model

<p align=center>
    <img alt="图 11" src="../img/9%20Referee%20Towards%20Reference-free%20Cross-speaker%20Style%20Transfer%20With%20Low-quality%20Data%20For%20Expressive%20Speech%20Synthesis/IMG_20220308-160951218.png", width='60%'>
</p>

<p align=center>
    <img alt="图 12" src="../img/9%20Referee%20Towards%20Reference-free%20Cross-speaker%20Style%20Transfer%20With%20Low-quality%20Data%20For%20Expressive%20Speech%20Synthesis/IMG_20220308-163612786.png", width='60%'>
</p>

Cross-speaker style transfer (CSST), Phonetic PosteriorGram (PPG), style-to-wave (S2W) model
这篇是把Meta-Stylespeech的SALN和Discriminator都拿来用到中文TTS上了

### Modules

## Training and inference

## Experiment

### Dataset

1. Two internal Chinese corpora

> The low-quality multi-style audio-book corpus contains 38 speakers (each has only one speaking style) and in total has 28.8 hours speech data (0.76 hours/speaker). Sampling rate of some audio samples is 16 KHz. We resample all audio to 24 KHz.

### Metrics
